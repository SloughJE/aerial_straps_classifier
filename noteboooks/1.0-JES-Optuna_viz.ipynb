{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "import pandas as pd\n",
    "from matplotlib.animation import FuncAnimation, writers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 662, 'max_depth': 15, 'learning_rate': 0.03793986414727196, 'min_child_weight': 6, 'subsample': 0.6851872068200734, 'colsample_bytree': 0.5428988782954}\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where your database file is stored\n",
    "models_dir = '../models/dev'\n",
    "model_dir = os.path.join(models_dir, 'xgb')\n",
    "\n",
    "# Specify the SQLite database URL\n",
    "storage = f'sqlite:///{os.path.join(model_dir, \"optuna_study.db\")}'\n",
    "\n",
    "# Specify the study name\n",
    "study_name = \"xgb_optimization_study\"\n",
    "\n",
    "# Load the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# Now the study is loaded and you can use it, for example, to get the best parameters\n",
    "best_params = study.best_params\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial #0: {'n_estimators': 943, 'max_depth': 1, 'learning_rate': 0.15053669732374644, 'min_child_weight': 1, 'subsample': 0.5261103061095684, 'colsample_bytree': 0.5856265350275747}, Value: 0.6714462947424178\n",
      "Trial #1: {'n_estimators': 962, 'max_depth': 13, 'learning_rate': 0.16011069942838904, 'min_child_weight': 4, 'subsample': 0.780749569097481, 'colsample_bytree': 0.6245912875301148}, Value: 0.7035430446419857\n",
      "Trial #2: {'n_estimators': 975, 'max_depth': 20, 'learning_rate': 0.17059837747888135, 'min_child_weight': 1, 'subsample': 0.568504776746979, 'colsample_bytree': 0.9716977251888916}, Value: 0.7057691101967848\n",
      "Trial #3: {'n_estimators': 844, 'max_depth': 19, 'learning_rate': 0.1096570864563644, 'min_child_weight': 9, 'subsample': 0.6520448480096908, 'colsample_bytree': 0.9625061483298505}, Value: 0.7016371283919496\n",
      "Trial #4: {'n_estimators': 843, 'max_depth': 3, 'learning_rate': 0.2243859543037952, 'min_child_weight': 7, 'subsample': 0.8917482655364385, 'colsample_bytree': 0.8892711235654187}, Value: 0.7019143881297442\n",
      "Trial #5: {'n_estimators': 452, 'max_depth': 13, 'learning_rate': 0.2897251671382221, 'min_child_weight': 9, 'subsample': 0.675582768644212, 'colsample_bytree': 0.7429237410583753}, Value: 0.6956156847201942\n",
      "Trial #6: {'n_estimators': 562, 'max_depth': 3, 'learning_rate': 0.11667055619119703, 'min_child_weight': 7, 'subsample': 0.6012625791275085, 'colsample_bytree': 0.742088639212291}, Value: 0.7092568848275201\n",
      "Trial #7: {'n_estimators': 790, 'max_depth': 7, 'learning_rate': 0.2498109810427469, 'min_child_weight': 3, 'subsample': 0.6355190237001149, 'colsample_bytree': 0.8305827974099469}, Value: 0.703188718221619\n",
      "Trial #8: {'n_estimators': 384, 'max_depth': 12, 'learning_rate': 0.17961579427668478, 'min_child_weight': 3, 'subsample': 0.9760576524404391, 'colsample_bytree': 0.6672914145839288}, Value: 0.7032440776111321\n",
      "Trial #9: {'n_estimators': 911, 'max_depth': 6, 'learning_rate': 0.15592158459002503, 'min_child_weight': 1, 'subsample': 0.663380772158175, 'colsample_bytree': 0.7639678554986628}, Value: 0.7063435614679373\n",
      "Trial #10: {'n_estimators': 73, 'max_depth': 7, 'learning_rate': 0.023010773818033875, 'min_child_weight': 7, 'subsample': 0.7725891490320966, 'colsample_bytree': 0.5188418862817192}, Value: 0.6922724281513025\n",
      "Trial #11: {'n_estimators': 633, 'max_depth': 7, 'learning_rate': 0.10164959985100322, 'min_child_weight': 6, 'subsample': 0.5016423853359302, 'colsample_bytree': 0.7499077389084474}, Value: 0.703228405871702\n",
      "Trial #12: {'n_estimators': 635, 'max_depth': 4, 'learning_rate': 0.09687660524197902, 'min_child_weight': 5, 'subsample': 0.5874459435030656, 'colsample_bytree': 0.8079612903861373}, Value: 0.7063192801156843\n",
      "Trial #13: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.05532439967487052, 'min_child_weight': 10, 'subsample': 0.7079541429900951, 'colsample_bytree': 0.7060122426431392}, Value: 0.7069891705314667\n",
      "Trial #14: {'n_estimators': 245, 'max_depth': 1, 'learning_rate': 0.04028023917374651, 'min_child_weight': 10, 'subsample': 0.7204928585011531, 'colsample_bytree': 0.68866128571012}, Value: 0.6552826007460535\n",
      "Trial #15: {'n_estimators': 283, 'max_depth': 10, 'learning_rate': 0.047620167417415885, 'min_child_weight': 8, 'subsample': 0.7306250560659096, 'colsample_bytree': 0.7030102536088831}, Value: 0.705728589360208\n",
      "Trial #16: {'n_estimators': 586, 'max_depth': 4, 'learning_rate': 0.06282810611251657, 'min_child_weight': 10, 'subsample': 0.5944027812816931, 'colsample_bytree': 0.6413317608696172}, Value: 0.7074331992237106\n",
      "Trial #17: {'n_estimators': 627, 'max_depth': 10, 'learning_rate': 0.011217044920168118, 'min_child_weight': 8, 'subsample': 0.5947243081838229, 'colsample_bytree': 0.615155208366605}, Value: 0.710125566661119\n",
      "Trial #18: {'n_estimators': 733, 'max_depth': 16, 'learning_rate': 0.029541247038872082, 'min_child_weight': 7, 'subsample': 0.5426688655299281, 'colsample_bytree': 0.5745543558050492}, Value: 0.7098416604531614\n",
      "Trial #19: {'n_estimators': 729, 'max_depth': 16, 'learning_rate': 0.027684889679885555, 'min_child_weight': 6, 'subsample': 0.5311735663966337, 'colsample_bytree': 0.5026666699657647}, Value: 0.7092139135063675\n",
      "Trial #20: {'n_estimators': 711, 'max_depth': 16, 'learning_rate': 0.01441898200782114, 'min_child_weight': 8, 'subsample': 0.5607900476691847, 'colsample_bytree': 0.5735297053139946}, Value: 0.7058246408317681\n",
      "Trial #21: {'n_estimators': 513, 'max_depth': 10, 'learning_rate': 0.012690280074875993, 'min_child_weight': 7, 'subsample': 0.6075625917332315, 'colsample_bytree': 0.5876551244477345}, Value: 0.710973058106697\n",
      "Trial #22: {'n_estimators': 471, 'max_depth': 10, 'learning_rate': 0.015362998360477033, 'min_child_weight': 8, 'subsample': 0.6103957239254447, 'colsample_bytree': 0.566455676922915}, Value: 0.7107250866016356\n",
      "Trial #23: {'n_estimators': 473, 'max_depth': 10, 'learning_rate': 0.010047490687833636, 'min_child_weight': 8, 'subsample': 0.6199942458459001, 'colsample_bytree': 0.6160564757599166}, Value: 0.7042507166094456\n",
      "Trial #24: {'n_estimators': 376, 'max_depth': 9, 'learning_rate': 0.071693072246439, 'min_child_weight': 9, 'subsample': 0.6231056599656313, 'colsample_bytree': 0.5509011566457087}, Value: 0.7082400134163205\n",
      "Trial #25: {'n_estimators': 491, 'max_depth': 12, 'learning_rate': 0.010652866522879003, 'min_child_weight': 5, 'subsample': 0.5049630727993977, 'colsample_bytree': 0.534040404508729}, Value: 0.7076133270020627\n",
      "Trial #26: {'n_estimators': 391, 'max_depth': 9, 'learning_rate': 0.07277580971545387, 'min_child_weight': 8, 'subsample': 0.5737926291873889, 'colsample_bytree': 0.6003097372368775}, Value: 0.7053347243267348\n",
      "Trial #27: {'n_estimators': 655, 'max_depth': 14, 'learning_rate': 0.03869163609034511, 'min_child_weight': 6, 'subsample': 0.6918411276426585, 'colsample_bytree': 0.5542505786295915}, Value: 0.710047206436622\n",
      "Trial #28: {'n_estimators': 518, 'max_depth': 9, 'learning_rate': 0.049331118796834564, 'min_child_weight': 9, 'subsample': 0.6436868344089222, 'colsample_bytree': 0.6515145813955948}, Value: 0.7073928568703926\n",
      "Trial #29: {'n_estimators': 178, 'max_depth': 11, 'learning_rate': 0.07223146553011388, 'min_child_weight': 8, 'subsample': 0.5455680904776967, 'colsample_bytree': 0.598662308228907}, Value: 0.7083975137163433\n",
      "Trial #30: {'n_estimators': 592, 'max_depth': 8, 'learning_rate': 0.03669330849472589, 'min_child_weight': 7, 'subsample': 0.6095879455945364, 'colsample_bytree': 0.5730704074425241}, Value: 0.7059313646728527\n",
      "Trial #31: {'n_estimators': 662, 'max_depth': 15, 'learning_rate': 0.03793986414727196, 'min_child_weight': 6, 'subsample': 0.6851872068200734, 'colsample_bytree': 0.5428988782954}, Value: 0.711542272961385\n",
      "Trial #32: {'n_estimators': 425, 'max_depth': 14, 'learning_rate': 0.010795831630622473, 'min_child_weight': 5, 'subsample': 0.6844621528561601, 'colsample_bytree': 0.5009424769104649}, Value: 0.7087084040077919\n",
      "Trial #33: {'n_estimators': 539, 'max_depth': 11, 'learning_rate': 0.030028389890219113, 'min_child_weight': 6, 'subsample': 0.6500401955896044, 'colsample_bytree': 0.617680503534327}, Value: 0.7085775583914387\n",
      "Trial #34: {'n_estimators': 665, 'max_depth': 18, 'learning_rate': 0.056353003353746045, 'min_child_weight': 4, 'subsample': 0.5904835454683246, 'colsample_bytree': 0.540146625239156}, Value: 0.7093118321064893\n",
      "Trial #35: {'n_estimators': 774, 'max_depth': 13, 'learning_rate': 0.02540186545503488, 'min_child_weight': 7, 'subsample': 0.5668450833212485, 'colsample_bytree': 0.6302198479525907}, Value: 0.7109194884060661\n",
      "Trial #36: {'n_estimators': 892, 'max_depth': 14, 'learning_rate': 0.03792048426622656, 'min_child_weight': 7, 'subsample': 0.5709535671058528, 'colsample_bytree': 0.5856906135134666}, Value: 0.7071194910969124\n",
      "Trial #37: {'n_estimators': 822, 'max_depth': 17, 'learning_rate': 0.08363493953383708, 'min_child_weight': 6, 'subsample': 0.6607782761613149, 'colsample_bytree': 0.6359954201289348}, Value: 0.7072345051188129\n",
      "Trial #38: {'n_estimators': 975, 'max_depth': 13, 'learning_rate': 0.13197638177613738, 'min_child_weight': 4, 'subsample': 0.6281526810320538, 'colsample_bytree': 0.5556625324166674}, Value: 0.7032821832991948\n",
      "Trial #39: {'n_estimators': 758, 'max_depth': 20, 'learning_rate': 0.08966410142954669, 'min_child_weight': 7, 'subsample': 0.5545671953283181, 'colsample_bytree': 0.5266516723407555}, Value: 0.7056394474272266\n",
      "Trial #40: {'n_estimators': 675, 'max_depth': 15, 'learning_rate': 0.05571068844387792, 'min_child_weight': 9, 'subsample': 0.6748458680761339, 'colsample_bytree': 0.6614506143911969}, Value: 0.7067318485370144\n",
      "Trial #41: {'n_estimators': 595, 'max_depth': 12, 'learning_rate': 0.022408436326724228, 'min_child_weight': 8, 'subsample': 0.6075629928036664, 'colsample_bytree': 0.6031657293270127}, Value: 0.70479728610784\n",
      "Trial #42: {'n_estimators': 526, 'max_depth': 13, 'learning_rate': 0.023220004399133003, 'min_child_weight': 7, 'subsample': 0.5777069310409354, 'colsample_bytree': 0.6230609518856094}, Value: 0.7081937954074007\n",
      "Trial #43: {'n_estimators': 821, 'max_depth': 11, 'learning_rate': 0.04471865737992431, 'min_child_weight': 8, 'subsample': 0.6353135186789894, 'colsample_bytree': 0.5888593537940915}, Value: 0.705412345373449\n",
      "Trial #44: {'n_estimators': 329, 'max_depth': 8, 'learning_rate': 0.024605889000195558, 'min_child_weight': 9, 'subsample': 0.5258061155975453, 'colsample_bytree': 0.5673980702172101}, Value: 0.7091106581543164\n",
      "Trial #45: {'n_estimators': 696, 'max_depth': 10, 'learning_rate': 0.042110516832463946, 'min_child_weight': 7, 'subsample': 0.6070574539502217, 'colsample_bytree': 0.5410808034945378}, Value: 0.7076424539931307\n",
      "Trial #46: {'n_estimators': 771, 'max_depth': 12, 'learning_rate': 0.06296543605970185, 'min_child_weight': 5, 'subsample': 0.6559861072856539, 'colsample_bytree': 0.6302758631349337}, Value: 0.7072695147320133\n",
      "Trial #47: {'n_estimators': 616, 'max_depth': 8, 'learning_rate': 0.016630210176576767, 'min_child_weight': 6, 'subsample': 0.6962228451652233, 'colsample_bytree': 0.6680044419018961}, Value: 0.710187833327357\n",
      "Trial #48: {'n_estimators': 441, 'max_depth': 6, 'learning_rate': 0.0340692620329788, 'min_child_weight': 6, 'subsample': 0.7497256152518392, 'colsample_bytree': 0.6756507602328328}, Value: 0.7067942206021394\n",
      "Trial #49: {'n_estimators': 887, 'max_depth': 8, 'learning_rate': 0.04812954538891522, 'min_child_weight': 2, 'subsample': 0.6924516527524929, 'colsample_bytree': 0.6431561292845142}, Value: 0.7102183702180916\n",
      "Trial #50: {'n_estimators': 893, 'max_depth': 15, 'learning_rate': 0.04793464637543664, 'min_child_weight': 2, 'subsample': 0.7136701967668669, 'colsample_bytree': 0.6477369592019577}, Value: 0.7106471876603391\n",
      "Trial #51: {'n_estimators': 895, 'max_depth': 15, 'learning_rate': 0.05126838891731827, 'min_child_weight': 2, 'subsample': 0.7285800366063625, 'colsample_bytree': 0.5919507279305395}, Value: 0.7096575658444402\n",
      "Trial #9: {'n_estimators': 911, 'max_depth': 6, 'learning_rate': 0.15592158459002503, 'min_child_weight': 1, 'subsample': 0.663380772158175, 'colsample_bytree': 0.7639678554986628}, Value: 0.7063435614679373\n"
     ]
    }
   ],
   "source": [
    "# List all trials in the study\n",
    "all_trials = study.trials\n",
    "for trial in all_trials:\n",
    "    print(f\"Trial #{trial.number}: {trial.params}, Value: {trial.value}\")\n",
    "\n",
    "# Access a specific trial by trial number\n",
    "trial_number = 10  # Replace with the desired trial number\n",
    "specific_trial = study.trials[trial_number - 1]\n",
    "print(f\"Trial #{specific_trial.number}: {specific_trial.params}, Value: {specific_trial.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trials data\n",
    "num_trials = 10\n",
    "trials = study.trials_dataframe()[0:num_trials]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_steps = 10  # Number of interpolation steps between each pair of trials\n",
    "\n",
    "# Columns to interpolate\n",
    "interpolate_columns = [\n",
    "    'params_colsample_bytree', 'params_learning_rate', 'params_max_depth', \n",
    "    'params_min_child_weight', 'params_n_estimators', 'params_subsample',\n",
    "    'value'\n",
    "]\n",
    "\n",
    "# Columns to retain without interpolation\n",
    "retain_columns = [\n",
    "    'number', 'datetime_start', 'datetime_complete', 'duration', 'state'\n",
    "]\n",
    "\n",
    "# Create a list to store the DataFrames with the interpolated values for each pair of trials\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(trials) - 1):\n",
    "    # Get the hyperparameter values for the current and next trial\n",
    "    current_values = trials.iloc[i][interpolate_columns].values\n",
    "    next_values = trials.iloc[i + 1][interpolate_columns].values\n",
    "    \n",
    "    # Create a dictionary with interpolated values for each hyperparameter\n",
    "    data = {col: np.linspace(current_values[j], next_values[j], interp_steps) for j, col in enumerate(interpolate_columns)}\n",
    "    \n",
    "    # Add the retained values to the dictionary\n",
    "    for col in retain_columns:\n",
    "        data[col] = [trials.iloc[i][col]] * interp_steps\n",
    "    \n",
    "    # Create a DataFrame with the interpolated and retained values and add it to the list\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames to create a single DataFrame with all interpolated values\n",
    "# Add the last trial to the end of the interpolated DataFrame\n",
    "last_trial = trials.iloc[-1].copy()\n",
    "for col in interpolate_columns:\n",
    "    last_trial[col] = [trials.iloc[-1][col]]\n",
    "for col in retain_columns:\n",
    "    last_trial[col] = [trials.iloc[-1][col]]\n",
    "\n",
    "# Add the last trial to the end of the interpolated DataFrame\n",
    "last_trial = trials.iloc[-1:].copy()  # This will return a DataFrame with a single row\n",
    "\n",
    "# Append the last trial data as a new row in the DataFrame\n",
    "dfs.append(last_trial)\n",
    "interpolated_trials = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>value</th>\n",
       "      <th>number</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.731742</td>\n",
       "      <td>0.163820</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>735.333333</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.705310</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-09-15 19:08:26.860395</td>\n",
       "      <td>2023-09-15 19:08:33.551027</td>\n",
       "      <td>0 days 00:00:06.690632</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.742484</td>\n",
       "      <td>0.161187</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>793.888889</td>\n",
       "      <td>0.732865</td>\n",
       "      <td>0.705655</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-09-15 19:08:26.860395</td>\n",
       "      <td>2023-09-15 19:08:33.551027</td>\n",
       "      <td>0 days 00:00:06.690632</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.753226</td>\n",
       "      <td>0.158554</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>852.444444</td>\n",
       "      <td>0.698123</td>\n",
       "      <td>0.705999</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-09-15 19:08:26.860395</td>\n",
       "      <td>2023-09-15 19:08:33.551027</td>\n",
       "      <td>0 days 00:00:06.690632</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.763968</td>\n",
       "      <td>0.155922</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>911.000000</td>\n",
       "      <td>0.663381</td>\n",
       "      <td>0.706344</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-09-15 19:08:26.860395</td>\n",
       "      <td>2023-09-15 19:08:33.551027</td>\n",
       "      <td>0 days 00:00:06.690632</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.763968</td>\n",
       "      <td>0.155922</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>911.000000</td>\n",
       "      <td>0.663381</td>\n",
       "      <td>0.706344</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-09-15 19:08:33.582719</td>\n",
       "      <td>2023-09-15 19:09:27.067142</td>\n",
       "      <td>0 days 00:00:53.484423</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    params_colsample_bytree  params_learning_rate  params_max_depth  \\\n",
       "86                 0.731742              0.163820          8.000000   \n",
       "87                 0.742484              0.161187          7.333333   \n",
       "88                 0.753226              0.158554          6.666667   \n",
       "89                 0.763968              0.155922          6.000000   \n",
       "90                 0.763968              0.155922          6.000000   \n",
       "\n",
       "    params_min_child_weight  params_n_estimators  params_subsample     value  \\\n",
       "86                 1.666667           735.333333          0.767606  0.705310   \n",
       "87                 1.444444           793.888889          0.732865  0.705655   \n",
       "88                 1.222222           852.444444          0.698123  0.705999   \n",
       "89                 1.000000           911.000000          0.663381  0.706344   \n",
       "90                 1.000000           911.000000          0.663381  0.706344   \n",
       "\n",
       "    number             datetime_start          datetime_complete  \\\n",
       "86       8 2023-09-15 19:08:26.860395 2023-09-15 19:08:33.551027   \n",
       "87       8 2023-09-15 19:08:26.860395 2023-09-15 19:08:33.551027   \n",
       "88       8 2023-09-15 19:08:26.860395 2023-09-15 19:08:33.551027   \n",
       "89       8 2023-09-15 19:08:26.860395 2023-09-15 19:08:33.551027   \n",
       "90       9 2023-09-15 19:08:33.582719 2023-09-15 19:09:27.067142   \n",
       "\n",
       "                 duration     state  \n",
       "86 0 days 00:00:06.690632  COMPLETE  \n",
       "87 0 days 00:00:06.690632  COMPLETE  \n",
       "88 0 days 00:00:06.690632  COMPLETE  \n",
       "89 0 days 00:00:06.690632  COMPLETE  \n",
       "90 0 days 00:00:53.484423  COMPLETE  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_trials.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interpolated_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import viridis\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#face_color = viridis(0)\n",
    "face_color = 'black'\n",
    "fig = plt.figure(figsize=(16, 16), dpi=300, facecolor=face_color) # have to have a background for ffmpeg\n",
    "gs = gridspec.GridSpec(4, 1)\n",
    "\n",
    "# ax = fig.add_subplot(2, 1, 2, projection='3d', frame_on=False)\n",
    "ax = plt.subplot(gs[1:4], projection='3d', frame_on=False)\n",
    "\n",
    "ax.grid(False)\n",
    "ax.xaxis.pane.fill = ax.yaxis.pane.fill = ax.zaxis.pane.fill = False  # Make panes transparent\n",
    "ax.xaxis.pane.set_edgecolor('w')\n",
    "ax.yaxis.pane.set_edgecolor('w')\n",
    "ax.zaxis.pane.set_edgecolor('w')\n",
    "ax.xaxis.pane.set_linewidth(0)\n",
    "ax.yaxis.pane.set_linewidth(0)\n",
    "ax.zaxis.pane.set_linewidth(0)\n",
    "ax.xaxis.line.set_lw(0.)  # Hide the x axis\n",
    "ax.yaxis.line.set_lw(0.)  # Hide the y axis\n",
    "ax.zaxis.line.set_lw(0.)  # Hide the z axis\n",
    "\n",
    "# Hide axes ticks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "# Create a secondary subplot for the time series plot\n",
    "ax2 = plt.subplot(gs[0:1])\n",
    "#ax2 = fig.add_subplot(2, 1, 1)\n",
    "ax2.set_xlabel('Trial Number')\n",
    "ax2.set_ylabel('Optimized Value')\n",
    "ax2.set_title('Optimization Progress')\n",
    "\n",
    "\n",
    "ls = 1000\n",
    "# Define the grid for plotting the distributions\n",
    "dist_size = 4\n",
    "x = np.linspace(-dist_size, dist_size, ls)\n",
    "y = np.linspace(-dist_size, dist_size, ls)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Define the grid for plotting the base surface\n",
    "x_base = np.linspace(-5, 5, ls)\n",
    "y_base = np.linspace(-5, 5, ls)\n",
    "X_base, Y_base = np.meshgrid(x_base, y_base)\n",
    "\n",
    "# Define the variances for the distributions (you can adjust these values)\n",
    "sing_var = 0.15\n",
    "variances = [sing_var, sing_var, sing_var, sing_var, sing_var, sing_var]\n",
    "\n",
    "# Define unique coordinates for each hyperparameter\n",
    "coord_dist = 2\n",
    "coordinates = [\n",
    "    [-coord_dist, -coord_dist], [-coord_dist, coord_dist], \n",
    "    [coord_dist, -coord_dist], [coord_dist, coord_dist], \n",
    "    [0, -coord_dist], [0, coord_dist]\n",
    "]\n",
    "# Get the minimum and maximum values for each hyperparameter across all trials\n",
    "min_values = interpolated_trials[['params_n_estimators', 'params_max_depth', 'params_learning_rate', 'params_min_child_weight', 'params_subsample', 'params_colsample_bytree']].min()\n",
    "max_values = interpolated_trials[['params_n_estimators', 'params_max_depth', 'params_learning_rate', 'params_min_child_weight', 'params_subsample', 'params_colsample_bytree']].max()\n",
    "# Get the minimum and maximum trial numbers\n",
    "min_trial_num = interpolated_trials['number'].min()\n",
    "max_trial_num = interpolated_trials['number'].max()\n",
    "# Get the minimum and maximum values of the 'value' column\n",
    "min_value = interpolated_trials['value'].min()\n",
    "max_value = interpolated_trials['value'].max()\n",
    "margin = 0.05  # 5% margin\n",
    "value_range = max_value - min_value\n",
    "\n",
    "def update(num, trials, variances, coordinates, ax):\n",
    "    #print(num)\n",
    "    ax.cla()\n",
    "    ax.set_facecolor(face_color)\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.pane.fill = ax.yaxis.pane.fill = ax.zaxis.pane.fill = False  # Make panes transparent\n",
    "    ax.xaxis.line.set_lw(0.)  # Hide the x axis\n",
    "    ax.yaxis.line.set_lw(0.)  # Hide the y axis\n",
    "    ax.zaxis.line.set_lw(0.)  # Hide the z axis\n",
    "    \n",
    "    # Hide axes ticks and labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    #ax.plot_surface(X_base, Y_base, np.zeros_like(X_base) - 0.01, color=plt.cm.viridis(0), alpha=0.1, linewidth=0, antialiased=False)\n",
    "    trial_num = num / interp_steps\n",
    "\n",
    "    # Clear the subplot to avoid overlaying of data\n",
    "    ax2.clear()  \n",
    "    ax2.set_facecolor(face_color)\n",
    "    # Set the x-limits to keep the x-axis fixed\n",
    "    ax2.set_xlim(0, len(interpolated_trials) - 1)\n",
    "    ax2.set_ylim(min_value - margin * value_range, max_value + margin * value_range)\n",
    "    ax2.set_title('Optimization Progress')\n",
    "\n",
    "    cmap = plt.cm.RdYlGn\n",
    "    # Get the normalized values for the color mapping\n",
    "    normalized_values = (interpolated_trials['value'][:num+1] - min_value) / (max_value - min_value)\n",
    "    # Get the colors corresponding to the normalized values\n",
    "    colors = cmap(normalized_values)\n",
    "    # Plot individual line segments with different colors\n",
    "    for i in range(num):\n",
    "        ax2.plot([i, i+1], interpolated_trials['value'][i:i+2], color=colors[i], linewidth=4)\n",
    "\n",
    "    # Get the normalized value for the current trial\n",
    "    current_normalized_value = (interpolated_trials.iloc[num]['value'] - min_value) / (max_value - min_value)\n",
    "    # Get the color corresponding to the normalized value\n",
    "    current_color = cmap(current_normalized_value)\n",
    "\n",
    "    ax.text2D(0.05, 0.95, f\"Trial: {num // interp_steps}\", transform=ax.transAxes, fontsize=32, va='top', ha='left', color='white')\n",
    "    ax.text2D(0.05, 0.90, f\"Optimized Value: {interpolated_trials.iloc[num]['value']:.4f}\", transform=ax.transAxes, fontsize=32, va='top', ha='left', color=current_color)\n",
    "\n",
    "    # Get the hyperparameter values for the current trial\n",
    "    params = interpolated_trials.iloc[num][['params_n_estimators', 'params_max_depth', \n",
    "                                            'params_learning_rate', 'params_min_child_weight', 'params_subsample', 'params_colsample_bytree']].values\n",
    "    \n",
    "    # Normalize the hyperparameter values to be between 0 and 1 using the min and max values from all trials\n",
    "    params_normalized = (params - min_values.values) / (max_values.values - min_values.values)+.01 # add constant so we see SOMETHING\n",
    "\n",
    "    #print(params_normalized)\n",
    "    # Plot a 3D Gaussian distribution for each hyperparameter\n",
    "    for i, (param, variance, coord) in enumerate(zip(params_normalized, variances, coordinates)):\n",
    "        pos = np.dstack((X, Y))\n",
    "        #print(pos)\n",
    "        rv = multivariate_normal(coord, [[variance, 0], [0, variance]])\n",
    "        Z = rv.pdf(pos) * param\n",
    "        Z[Z < 0.00001] = np.nan  # Set a threshold to remove low Z values\n",
    "        ax.plot_surface(X + coord[0], Y + coord[1], Z, cmap='viridis', linewidth=0, alpha=1)\n",
    "    \n",
    "    # Plot the base surface again with a high transparency value\n",
    "    #ax.plot_surface(X_base, Y_base, np.zeros_like(X_base) - 0.1, color=plt.cm.viridis(0), alpha=0.2, linewidth=0, antialiased=False)\n",
    "    \n",
    "    ax.set_xlim(-5, 5)  # Set the limits to provide more space around the edges\n",
    "    ax.set_ylim(-6, 6)  # Set the limits to provide more space around the edges\n",
    "   \n",
    "# Create an animation\n",
    "ani = FuncAnimation(fig, update, frames=len(interpolated_trials), fargs=(interpolated_trials, variances, coordinates, ax), interval=10)\n",
    "\n",
    "# Save the animation\n",
    "#ani.save('hyperparameter_optimization_FULL.gif', writer='pillow', dpi=300)  # Adjust dpi as needed\n",
    "\n",
    "# Specify the writer\n",
    "writer = writers['ffmpeg'](fps=24, metadata=dict(artist='Me'), bitrate=3000)\n",
    "\n",
    "# Save the animation\n",
    "ani.save('hyperparameter_optimization_larger.mp4', writer=writer, dpi=300)  # Adjust dpi as needed\n",
    "\n",
    "# Display the animation\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>value</th>\n",
       "      <th>number</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585627</td>\n",
       "      <td>0.150537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>943.000000</td>\n",
       "      <td>0.526110</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-15 19:02:06.533305</td>\n",
       "      <td>2023-09-15 19:02:13.475305</td>\n",
       "      <td>0 days 00:00:06.942000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.589956</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>945.111111</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.675013</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-15 19:02:06.533305</td>\n",
       "      <td>2023-09-15 19:02:13.475305</td>\n",
       "      <td>0 days 00:00:06.942000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594285</td>\n",
       "      <td>0.152664</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>947.222222</td>\n",
       "      <td>0.582697</td>\n",
       "      <td>0.678579</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-15 19:02:06.533305</td>\n",
       "      <td>2023-09-15 19:02:13.475305</td>\n",
       "      <td>0 days 00:00:06.942000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598615</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>949.333333</td>\n",
       "      <td>0.610990</td>\n",
       "      <td>0.682145</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-15 19:02:06.533305</td>\n",
       "      <td>2023-09-15 19:02:13.475305</td>\n",
       "      <td>0 days 00:00:06.942000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602944</td>\n",
       "      <td>0.154792</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>951.444444</td>\n",
       "      <td>0.639283</td>\n",
       "      <td>0.685712</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-15 19:02:06.533305</td>\n",
       "      <td>2023-09-15 19:02:13.475305</td>\n",
       "      <td>0 days 00:00:06.942000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   params_colsample_bytree  params_learning_rate  params_max_depth  \\\n",
       "0                 0.585627              0.150537          1.000000   \n",
       "1                 0.589956              0.151600          2.333333   \n",
       "2                 0.594285              0.152664          3.666667   \n",
       "3                 0.598615              0.153728          5.000000   \n",
       "4                 0.602944              0.154792          6.333333   \n",
       "\n",
       "   params_min_child_weight  params_n_estimators  params_subsample     value  \\\n",
       "0                 1.000000           943.000000          0.526110  0.671446   \n",
       "1                 1.333333           945.111111          0.554404  0.675013   \n",
       "2                 1.666667           947.222222          0.582697  0.678579   \n",
       "3                 2.000000           949.333333          0.610990  0.682145   \n",
       "4                 2.333333           951.444444          0.639283  0.685712   \n",
       "\n",
       "   number             datetime_start          datetime_complete  \\\n",
       "0       0 2023-09-15 19:02:06.533305 2023-09-15 19:02:13.475305   \n",
       "1       0 2023-09-15 19:02:06.533305 2023-09-15 19:02:13.475305   \n",
       "2       0 2023-09-15 19:02:06.533305 2023-09-15 19:02:13.475305   \n",
       "3       0 2023-09-15 19:02:06.533305 2023-09-15 19:02:13.475305   \n",
       "4       0 2023-09-15 19:02:06.533305 2023-09-15 19:02:13.475305   \n",
       "\n",
       "                duration     state  \n",
       "0 0 days 00:00:06.942000  COMPLETE  \n",
       "1 0 days 00:00:06.942000  COMPLETE  \n",
       "2 0 days 00:00:06.942000  COMPLETE  \n",
       "3 0 days 00:00:06.942000  COMPLETE  \n",
       "4 0 days 00:00:06.942000  COMPLETE  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=7, step=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_trials.index[:6+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=91, step=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_trials.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
